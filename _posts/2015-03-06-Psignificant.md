---
layout: post
title: The significance of 'psignificance'
---

Statistical significance is a concept that even established researchers get completely wrong. If you don't believe me, just read <a href="https://mchankins.wordpress.com/2013/04/21/still-not-significant-2/">the list of increasingly desperate descriptions of non-significant results</a> (compiled by <a href="https://twitter.com/mc_hankins">Matthew Hankins</a>).

I think this confusion is largely to do with language. After doing a hypothesis test, the word 'significant' has a precise meaning: it means that the probability of observing the given result if the null hypothesis was true has been calculated and found to be less than some arbitrary pre-determined significance level. This arbitrary level is usually taken to be 0.05, corresponding to a 1 in 20 chance that you'd see the same result if the null hypothesis were true. (If you followed that explanation you've almost certainly heard it before.)

However, this meaning of 'significant' is **different** to its everyday meaning.

<img class="alignnone" src="http://www.quickmeme.com/img/9d/9d488c4dd6b949416c85906c5bd7a4c3d3163632d5606a6a068e487c0f3a2d73.jpg" alt="" width="625" height="351" />

When you say a result is 'significant' to most non-statisticians, they're likely to start thinking of any of the following closely related words: notable, noteworthy, worthy of attention, remarkable, outstanding, important...this is clearly how it gets (mis)used in practice.

Conversely, saying a result is 'not significant' sounds like you're saying it is none of those things.

Is it any wonder that people become obsessed over whether the p-value passes that arbitrary <em>p &lt; 0.05</em> threshold when they hear in Applied Stats 101 that their result won't be **important*' unless it does?


Things are further complicated by the fact that 'clinical significance' is also a thing. I've noticed particularly in medical studies it's not uncommon talk about results as being 'significant' and imply that they're **clinically** significant or important, whereas in fact they're probably not.

The Wikipedia page on statistical significance stresses:

"The term <i>significance</i> does not imply <i>importance</i> and the term <i>statistical significance</i> is not the same as research, theoretical, or practical significance." (<a href="http://en.wikipedia.org/wiki/Statistical_significance">source</a>)

It's clear that this message has failed to get through to thousands of students and researchers.

Therefore, I would like to suggest a new word to be used in place of 'significant' after performing a hypothesis test:
<p style="text-align:center;"><strong>psignificant </strong>(pʰsɪɡˈnɪfɪk(ə)nt/)</p>
<p style="text-align:left;">When spoken, the <i><strong>p</strong> </i>at the start should to be aspirated ('puh-significant') to remind everyone that this interpretation is inextricably linked to a p-value from a statistical test and is not the same as the everyday meaning of 'significant'.</p>
With this new word, I look forward to statements like this appearing in published papers:

"the difference in values is psignificant (p &lt; 0.05) but is too small to be of clinical significance"

<hr />

This post is just a dumb suggestion. But I don't think it's fair to blame non-statisticians for misusing p-values when the language used to describe them is misleading. 

**EDIT:** It also turns out others have had this idea before, but it's not widely used. Maybe psignificance needs it's <a href="http://tauday.com/tau-manifesto">Tau Manifesto</a>.
